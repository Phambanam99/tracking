# Vessel Position Storage Optimization Strategy ðŸŽ¯

## âš ï¸ Váº¥n Äá»: Storage Explosion

### TÃ­nh ToÃ¡n Hiá»‡n Táº¡i:
- **28,869 vessels** Ä‘ang hoáº¡t Ä‘á»™ng
- **2 sources** (SignalR + AISStream.io)
- **Update frequency:** 5 giÃ¢y/láº§n
- **Records/ngÃ y:** ~100 triá»‡u records
- **Storage/ngÃ y:** ~100 GB
- **Storage/nÄƒm:** ~36 TB âŒ

â†’ **KHÃ”NG Bá»€N Vá»®NG!**

## âœ… Giáº£i PhÃ¡p: Tiered Storage Strategy

### Chiáº¿n LÆ°á»£c 3 Táº§ng:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 1: HOT DATA (Redis)                               â”‚
â”‚  - Last 1 hour                                          â”‚
â”‚  - Full resolution (all sources)                        â”‚
â”‚  - In-memory, ultra-fast                               â”‚
â”‚  - Size: ~2 GB                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 2: WARM DATA (PostgreSQL - Recent)                â”‚
â”‚  - Last 7 days                                          â”‚
â”‚  - FUSED data only (1 record per timestamp)            â”‚
â”‚  - Indexed for fast queries                            â”‚
â”‚  - Size: ~70 GB                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 3: COLD DATA (PostgreSQL - Archive)               â”‚
â”‚  - Older than 7 days                                    â”‚
â”‚  - DOWNSAMPLED (1 record per minute)                   â”‚
â”‚  - Compressed                                           â”‚
â”‚  - Size: ~5 GB/month                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“Š Chi Tiáº¿t Tá»«ng Táº§ng

### Tier 1: HOT DATA (Redis) - 1 Hour

**Má»¥c Ä‘Ã­ch:** Realtime tracking, ultra-fast queries

**LÆ°u gÃ¬:**
- âœ… **Táº¥t cáº£ sources** (Ä‘á»ƒ fusion cÃ³ Ä‘á»§ data)
- âœ… **Full resolution** (má»i update)
- âœ… **Geo-indexed** (cho bbox queries)

**Implementation:**
```typescript
// Redis keys:
ais:vessel:{mmsi}:recent        // Hash - latest position
ais:vessel:{mmsi}:history:1h    // Sorted Set - last 1 hour positions
ais:vessels:geo                 // Geo index
ais:vessels:active              // Sorted Set by timestamp

// TTL: 1 hour (auto-expire)
```

**Storage:**
```
28,869 vessels Ã— 720 records/hour Ã— 2 sources Ã— 100 bytes = ~4 GB
```

---

### Tier 2: WARM DATA (Postgres) - 7 Days

**Má»¥c Ä‘Ã­ch:** Recent history, detailed tracking

**LÆ°u gÃ¬:**
- âœ… **Chá»‰ FUSED data** (1 record tá»‘t nháº¥t má»—i timestamp)
- âŒ **KhÃ´ng lÆ°u táº¥t cáº£ sources** (tiáº¿t kiá»‡m 50% space)
- âœ… **Full resolution** (má»i update tá»« fusion)

**Schema Change:**
```prisma
model VesselPosition {
  id        Int      @id @default(autoincrement())
  vesselId  Int
  latitude  Float
  longitude Float
  speed     Float?
  course    Int?
  heading   Int?
  status    String?
  timestamp DateTime @default(now())
  source    String?   // Source cá»§a message tá»‘t nháº¥t
  score     Float?    // Score cá»§a message tá»‘t nháº¥t
  
  // âœ… Chá»‰ 1 record per timestamp (khÃ´ng phÃ¢n biá»‡t source)
  @@unique([vesselId, timestamp])  // â† Changed from [vesselId, timestamp, source]
  @@index([vesselId])
  @@index([timestamp])
  @@index([latitude, longitude])
  @@map("vessel_positions")
}

// âœ… Partition by date for easy archival
// CREATE TABLE vessel_positions_2025_11_08 PARTITION OF vessel_positions
// FOR VALUES FROM ('2025-11-08') TO ('2025-11-09');
```

**Storage:**
```
28,869 vessels Ã— 17,280 records/day Ã— 7 days Ã— 100 bytes = ~350 GB/week
Vá»›i compression: ~70 GB/week
```

**Auto-cleanup:**
```typescript
// Scheduled job: Delete data older than 7 days
@Cron('0 0 * * *')  // Daily at midnight
async cleanupOldPositions() {
  const sevenDaysAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000);
  
  await this.prisma.vesselPosition.deleteMany({
    where: {
      timestamp: { lt: sevenDaysAgo }
    }
  });
}
```

---

### Tier 3: COLD DATA (Archive) - Long-term

**Má»¥c Ä‘Ã­ch:** Historical analysis, compliance

**LÆ°u gÃ¬:**
- âœ… **DOWNSAMPLED** (1 record per minute thay vÃ¬ per 5 seconds)
- âœ… **Compressed** (PostgreSQL compression)
- âœ… **Separate table** (khÃ´ng áº£nh hÆ°á»Ÿng queries realtime)

**Schema:**
```prisma
model VesselPositionArchive {
  id        Int      @id @default(autoincrement())
  vesselId  Int
  latitude  Float
  longitude Float
  speed     Float?
  course    Int?
  heading   Int?
  timestamp DateTime  // Rounded to minute
  source    String?
  score     Float?
  
  // Aggregated data
  sampleCount Int?     // Sá»‘ samples Ä‘Æ°á»£c aggregate
  avgSpeed    Float?   // Average speed trong minute Ä‘Ã³
  
  @@unique([vesselId, timestamp])
  @@index([vesselId])
  @@index([timestamp])
  @@map("vessel_positions_archive")
}
```

**Downsampling Strategy:**
```typescript
@Cron('0 1 * * *')  // Daily at 1 AM
async archiveOldPositions() {
  const sevenDaysAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000);
  const eightDaysAgo = new Date(Date.now() - 8 * 24 * 60 * 60 * 1000);
  
  // Get positions from 7-8 days ago
  const positions = await this.prisma.vesselPosition.findMany({
    where: {
      timestamp: {
        gte: eightDaysAgo,
        lt: sevenDaysAgo
      }
    },
    orderBy: { timestamp: 'asc' }
  });
  
  // Group by vessel and minute
  const grouped = this.groupByMinute(positions);
  
  // Insert into archive (1 record per minute)
  for (const [key, group] of grouped) {
    const [vesselId, minute] = key.split(':');
    
    await this.prisma.vesselPositionArchive.create({
      data: {
        vesselId: parseInt(vesselId),
        latitude: group[0].latitude,  // First position in minute
        longitude: group[0].longitude,
        speed: group[0].speed,
        course: group[0].course,
        heading: group[0].heading,
        timestamp: new Date(minute),
        source: group[0].source,
        score: group[0].score,
        sampleCount: group.length,
        avgSpeed: this.average(group.map(p => p.speed)),
      }
    });
  }
  
  // Delete from main table
  await this.prisma.vesselPosition.deleteMany({
    where: {
      timestamp: {
        gte: eightDaysAgo,
        lt: sevenDaysAgo
      }
    }
  });
}

private groupByMinute(positions: VesselPosition[]) {
  const map = new Map<string, VesselPosition[]>();
  
  for (const pos of positions) {
    const minute = new Date(pos.timestamp);
    minute.setSeconds(0, 0);
    const key = `${pos.vesselId}:${minute.toISOString()}`;
    
    if (!map.has(key)) map.set(key, []);
    map.get(key)!.push(pos);
  }
  
  return map;
}
```

**Storage:**
```
28,869 vessels Ã— 1,440 records/day (1/min) Ã— 100 bytes = ~4 GB/day
Per month: ~120 GB
Per year: ~1.4 TB (vs 36 TB without optimization!)
```

## ðŸŽ¯ Cáº£i Tiáº¿n Fusion Pipeline

### Thay Äá»•i: Chá»‰ LÆ°u Message Tá»‘t Nháº¥t VÃ o DB

**File:** `backend/src/ais/ais-orchestrator.service.ts`

```typescript
private async processFusion(key: string, now: number) {
  try {
    const decision = await this.vesselFusion.decide(key, now);

    if (!decision.best) return;

    // âœ… Chá»‰ publish náº¿u lÃ  message má»›i
    if (decision.publish) {
      const fused = this.toFusedRecord(decision.best);
      this.fused$.next(fused);
      this.stats.published++;
      await this.vesselFusion.markPublished(key, decision.best.ts);
      
      // âœ… Chá»‰ persist message tá»‘t nháº¥t (khÃ´ng persist táº¥t cáº£)
      await this.persist(decision.best);
    }

    // âŒ REMOVED: KhÃ´ng persist backfillOnly ná»¯a
    // if (decision.backfillOnly) {
    //   await this.persist(decision.best);
    // }
  } catch (e: any) {
    this.logger.error(`processFusion failed for key ${key}: ${e.message}`);
  }
}
```

**Káº¿t quáº£:**
- âœ… Chá»‰ lÆ°u **1 record** má»—i timestamp (message tá»‘t nháº¥t)
- âœ… Giáº£m **50% storage** ngay láº­p tá»©c
- âœ… Váº«n giá»¯ Ä‘Æ°á»£c cháº¥t lÆ°á»£ng data (vÃ¬ Ä‘Ã£ chá»n message tá»‘t nháº¥t)

## ðŸ“ˆ So SÃ¡nh Storage

### TrÆ°á»›c Optimization:
```
Tier 1 (Redis):     4 GB
Tier 2 (Postgres):  700 GB (7 days, all sources)
Tier 3 (Archive):   36 TB/year
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL/year:         ~36 TB âŒ
```

### Sau Optimization:
```
Tier 1 (Redis):     4 GB (1 hour, all sources for fusion)
Tier 2 (Postgres):  70 GB (7 days, fused only)
Tier 3 (Archive):   1.4 TB/year (downsampled)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL/year:         ~1.4 TB âœ… (96% reduction!)
```

## ðŸš€ Implementation Plan

### Phase 1: Schema Migration (Immediate)
```bash
# 1. Create archive table
npx prisma migrate dev --name add_position_archive

# 2. Update unique constraint
# Change: @@unique([vesselId, timestamp, source])
# To:     @@unique([vesselId, timestamp])
npx prisma migrate dev --name remove_source_from_unique_key
```

### Phase 2: Update Fusion Logic (Immediate)
```typescript
// âœ… Only persist best message (not all sources)
if (decision.publish) {
  await this.persist(decision.best);
}
```

### Phase 3: Add Cleanup Jobs (Within 1 week)
```typescript
// 1. Daily cleanup: Delete positions older than 7 days
@Cron('0 0 * * *')
async cleanupOldPositions() { ... }

// 2. Daily archival: Downsample and move to archive
@Cron('0 1 * * *')
async archiveOldPositions() { ... }
```

### Phase 4: Redis TTL (Within 1 week)
```typescript
// Set TTL on Redis keys
await client.expire(`ais:vessel:${mmsi}:history:1h`, 3600);
```

## ðŸ“Š Query Patterns

### Recent Data (Last 7 days):
```typescript
// Fast - from main table
const positions = await prisma.vesselPosition.findMany({
  where: {
    vesselId: 922767,
    timestamp: { gte: sevenDaysAgo }
  },
  orderBy: { timestamp: 'desc' }
});
```

### Historical Data (Older than 7 days):
```typescript
// From archive table (downsampled)
const positions = await prisma.vesselPositionArchive.findMany({
  where: {
    vesselId: 922767,
    timestamp: {
      gte: thirtyDaysAgo,
      lt: sevenDaysAgo
    }
  },
  orderBy: { timestamp: 'desc' }
});
```

### Combined Query (Last 30 days):
```typescript
const [recent, archived] = await Promise.all([
  prisma.vesselPosition.findMany({
    where: { vesselId: 922767, timestamp: { gte: sevenDaysAgo } }
  }),
  prisma.vesselPositionArchive.findMany({
    where: { 
      vesselId: 922767, 
      timestamp: { gte: thirtyDaysAgo, lt: sevenDaysAgo }
    }
  })
]);

const combined = [...recent, ...archived].sort((a, b) => 
  b.timestamp.getTime() - a.timestamp.getTime()
);
```

## ðŸŽ¯ Trade-offs

### Pros:
- âœ… **96% storage reduction**
- âœ… **Faster queries** (smaller tables)
- âœ… **Lower costs** (database, backup)
- âœ… **Scalable** long-term

### Cons:
- âŒ **Máº¥t chi tiáº¿t** cá»§a tá»«ng source (chá»‰ giá»¯ message tá»‘t nháº¥t)
- âŒ **KhÃ´ng thá»ƒ audit** individual sources sau 7 ngÃ y
- âŒ **Downsampled** data sau 7 ngÃ y (1 record/minute thay vÃ¬ /5 seconds)

### Mitigation:
- Náº¿u cáº§n audit sources â†’ LÆ°u **source comparison logs** riÃªng (lightweight)
- Náº¿u cáº§n full resolution lÃ¢u dÃ i â†’ TÄƒng Tier 2 lÃªn 30 ngÃ y (trade-off: 300 GB)
- Náº¿u cáº§n raw data â†’ Export sang S3/cold storage (ráº» hÆ¡n nhiá»u)

## ðŸ” Monitoring

### Metrics to Track:
```typescript
// Storage metrics
SELECT 
  pg_size_pretty(pg_total_relation_size('vessel_positions')) as main_size,
  pg_size_pretty(pg_total_relation_size('vessel_positions_archive')) as archive_size;

// Record counts
SELECT 
  (SELECT COUNT(*) FROM vessel_positions) as recent_count,
  (SELECT COUNT(*) FROM vessel_positions_archive) as archive_count;

// Oldest record in main table
SELECT MIN(timestamp) FROM vessel_positions;
```

### Alerts:
- ðŸš¨ Main table > 7 days old data â†’ Cleanup job failed
- ðŸš¨ Main table > 100 GB â†’ Storage growing too fast
- ðŸš¨ Archive job failed â†’ Manual intervention needed

---

## âœ… Recommendation

**Implement Phase 1 + 2 IMMEDIATELY:**
1. Change unique constraint to `@@unique([vesselId, timestamp])`
2. Only persist best message (not all sources)
3. Add cleanup job for 7-day retention

**Expected Result:**
- 50% immediate storage reduction
- Sustainable growth (~1.4 TB/year)
- No impact on functionality

**Timeline:** 1-2 days implementation + testing

